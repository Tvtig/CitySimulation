Steps,Policy/Extrinsic Value Estimate,Policy/Entropy,Environment/Episode Length,Environment/Cumulative Reward,Policy/Extrinsic Reward,Is Training
2750000,2.2617724,1.0064526,296.53125,10.625,10.625,1.0
2760000,2.2892535,0.99589616,291.9032258064516,9.870967741935484,9.870967741935484,1.0
2770000,2.259116,0.9853097,316.45454545454544,9.727272727272727,9.727272727272727,1.0
2780000,2.3323958,0.99278915,302.6969696969697,9.818181818181818,9.818181818181818,1.0
2790000,2.3159895,0.9928173,300.0857142857143,10.228571428571428,10.228571428571428,1.0
2800000,2.339674,0.9843067,292.57142857142856,10.028571428571428,10.028571428571428,1.0
2810000,2.2717466,0.9759545,295.38235294117646,10.058823529411764,10.058823529411764,1.0
2820000,2.3364,0.9792338,298.06060606060606,10.242424242424242,10.242424242424242,1.0
2830000,2.4105136,0.9816115,287.05555555555554,9.666666666666666,9.666666666666666,1.0
2840000,2.3416631,0.9751948,294.3333333333333,10.242424242424242,10.242424242424242,1.0
2850000,2.3194091,0.97221506,298.5151515151515,10.121212121212121,10.121212121212121,1.0
2860000,2.3585474,0.9710177,290.22857142857146,9.8,9.8,1.0
2870000,2.3326266,0.9645153,303.7878787878788,10.303030303030303,10.303030303030303,1.0
2880000,2.3131344,0.968355,295.4375,10.3125,10.3125,1.0
2890000,2.2091289,0.95903695,293.25,10.28125,10.28125,1.0
2900000,2.2463968,0.9687309,312.11764705882354,10.294117647058824,10.294117647058824,1.0
